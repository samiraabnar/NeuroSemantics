{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nbrain_activations_2 = genfromtxt('../data/data_2.csv', delimiter=',')\\nbrain_activations_3 = genfromtxt('../data/data_3.csv', delimiter=',')\\nbrain_activations_4 = genfromtxt('../data/data_4.csv', delimiter=',')\\nbrain_activations_5 = genfromtxt('../data/data_5.csv', delimiter=',')\\nbrain_activations_6 = genfromtxt('../data/data_6.csv', delimiter=',')\\nbrain_activations_7 = genfromtxt('../data/data_7.csv', delimiter=',')\\nbrain_activations_8 = genfromtxt('../data/data_8.csv', delimiter=',')\\nbrain_activations_9 = genfromtxt('../data/data_9.csv', delimiter=',')\\n\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "import csv\n",
    "import sys\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2, activity_l2\n",
    "\n",
    "sys.path.append('../../')\n",
    "\n",
    "from NeuroLinguisticDecoding.src.WordEmbeddingLayer import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "brain_activations_1 = genfromtxt('../data/data.csv', delimiter=',')\n",
    "\"\"\"\n",
    "brain_activations_2 = genfromtxt('../data/data_2.csv', delimiter=',')\n",
    "brain_activations_3 = genfromtxt('../data/data_3.csv', delimiter=',')\n",
    "brain_activations_4 = genfromtxt('../data/data_4.csv', delimiter=',')\n",
    "brain_activations_5 = genfromtxt('../data/data_5.csv', delimiter=',')\n",
    "brain_activations_6 = genfromtxt('../data/data_6.csv', delimiter=',')\n",
    "brain_activations_7 = genfromtxt('../data/data_7.csv', delimiter=',')\n",
    "brain_activations_8 = genfromtxt('../data/data_8.csv', delimiter=',')\n",
    "brain_activations_9 = genfromtxt('../data/data_9.csv', delimiter=',')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 19750)\n",
      "(360, 19750)\n",
      "(360, 19750)\n",
      "(360, 19750)\n",
      "(360, 19750)\n",
      "(360, 19750)\n",
      "(360, 19750)\n",
      "(360, 19750)\n",
      "(360, 19750)\n",
      "(360, 21764)\n"
     ]
    }
   ],
   "source": [
    "print(brain_activations_1[:,:19750].shape)\n",
    "print(brain_activations_2[:,:19750].shape)\n",
    "print(brain_activations_3[:,:19750].shape)\n",
    "print(brain_activations_4[:,:19750].shape)\n",
    "print(brain_activations_5[:,:19750].shape)\n",
    "print(brain_activations_6[:,:19750].shape)\n",
    "print(brain_activations_7[:,:19750].shape)\n",
    "print(brain_activations_8[:,:19750].shape)\n",
    "print(brain_activations_9[:,:19750].shape)\n",
    "\n",
    "brain_activations = brain_activations_1\n",
    "\"\"\"np.concatenate((brain_activations_1[:,:19750],\n",
    "                        brain_activations_2[:,:19750],\n",
    "                        brain_activations_3[:,:19750],\n",
    "                        brain_activations_4[:,:19750],\n",
    "                        brain_activations_5[:,:19750],\n",
    "                        brain_activations_6[:,:19750],\n",
    "                        brain_activations_7[:,:19750],\n",
    "                        brain_activations_8[:,:19750],\n",
    "                        brain_activations_9[:,:19750]))\"\"\"\n",
    "\n",
    "\n",
    "print(brain_activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_1 = []\n",
    "with open('../data/words', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    words_1 = list(reader)\n",
    "    \n",
    "words = []\n",
    "words.extend(words_1)\n",
    "\n",
    "\n",
    "wem = WordEmbeddingLayer()\n",
    "wem.load_filtered_embedding(\"../data/neuro_words\")\n",
    "\n",
    "embedded_words = wem.embed(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "21764\n"
     ]
    }
   ],
   "source": [
    "print(len(embedded_words[0][0]))\n",
    "a = [ e[0] for e in embedded_words]\n",
    "print(brain_activations[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(input_dim = 300 ,output_dim=1000,_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01)))\n",
    "model.add(Dense(input_dim = 1000,output_dim=brain_activations[0].shape[0],_regularizer=l2(0.01), activity_regularizer=activity_l2(0.01)))\n",
    "model.compile(\"rmsprop\",\"mse\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 300)\n",
      "Epoch 1/100\n",
      "360/360 [==============================] - 47s - loss: 4.5595 - acc: 0.3083    \n",
      "Epoch 2/100\n",
      "360/360 [==============================] - 46s - loss: 0.3486 - acc: 0.6389    \n",
      "Epoch 3/100\n",
      "360/360 [==============================] - 47s - loss: 0.3302 - acc: 0.6528    \n",
      "Epoch 4/100\n",
      "360/360 [==============================] - 47s - loss: 0.3349 - acc: 0.6500    \n",
      "Epoch 5/100\n",
      "360/360 [==============================] - 709s - loss: 0.3345 - acc: 0.6472    \n",
      "Epoch 6/100\n",
      "360/360 [==============================] - 51s - loss: 0.3322 - acc: 0.6306    \n",
      "Epoch 7/100\n",
      "360/360 [==============================] - 48s - loss: 0.3626 - acc: 0.5667    \n",
      "Epoch 8/100\n",
      "360/360 [==============================] - 51s - loss: 0.3398 - acc: 0.6306    \n",
      "Epoch 9/100\n",
      "360/360 [==============================] - 49s - loss: 0.4000 - acc: 0.5639    \n",
      "Epoch 10/100\n",
      "360/360 [==============================] - 51s - loss: 0.3251 - acc: 0.6250    \n",
      "Epoch 11/100\n",
      "360/360 [==============================] - 51s - loss: 0.3434 - acc: 0.6083    \n",
      "Epoch 12/100\n",
      "360/360 [==============================] - 57s - loss: 0.3456 - acc: 0.6083    \n",
      "Epoch 13/100\n",
      "360/360 [==============================] - 71s - loss: 0.3231 - acc: 0.6306    \n",
      "Epoch 14/100\n",
      "360/360 [==============================] - 66s - loss: 0.3491 - acc: 0.6222    \n",
      "Epoch 15/100\n",
      "360/360 [==============================] - 64s - loss: 0.3156 - acc: 0.6389    \n",
      "Epoch 16/100\n",
      "360/360 [==============================] - 69s - loss: 0.7255 - acc: 0.5194    \n",
      "Epoch 17/100\n",
      "256/360 [====================>.........] - ETA: 22s - loss: 0.3245 - acc: 0.6367"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-15998a6fff1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membedded_words_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membedded_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_words_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded_words_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbrain_activations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    840\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedded_words_2 = np.asarray([ e[0] for e in embedded_words])\n",
    "print(embedded_words_2.shape)\n",
    "model.fit(embedded_words_2,brain_activations,nb_epoch=100)\n",
    "\n",
    "\n",
    "def calculate_accuracy(model,testX,testY):\n",
    "    Y = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "word_set = list(set([word[0] for word in words_1]))\n",
    "\n",
    "print(len(word_set))\n",
    "pairs = []\n",
    "for i in np.arange(60):\n",
    "    for j in np.arange(i):\n",
    "        pairs.append((i,j))\n",
    "\n",
    "all_activations = []\n",
    "all_features = []\n",
    "the_pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i,j) in pairs:\n",
    "    activations = []\n",
    "    the_pairs.append((i,j))\n",
    "    word_vectors = []\n",
    "    for k in np.arange(brain_activations.shape[0]):\n",
    "        if words[k][0] != word_set[i] and words[k][0] != word_set[j]:\n",
    "            activations.append(brain_activations[k])\n",
    "            word_vectors.append(embedded_words_2[k])\n",
    "    all_activations.append(activations)\n",
    "    all_features.append(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770\n",
      "1770\n",
      "1770\n",
      "348\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(len(all_activations))\n",
    "print(len(all_features))\n",
    "print(len(the_pairs))\n",
    "\n",
    "print(len(all_features[0]))\n",
    "print(embedded_words_2[10].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.3630 - acc: 0.2328     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.3071 - acc: 0.6437     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1076d57f0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.asarray(all_features[0]),np.asarray(all_activations[0]),nb_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(embedded_words_2[the_pairs[0][0]].shape)\n",
    "predicted_1 = model.predict(np.asarray([embedded_words_2[the_pairs[0][0]]]))\n",
    "predicted_2 = model.predict(np.asarray([embedded_words_2[the_pairs[0][1]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "from scipy import *\n",
    "from scipy.spatial.distance import *\n",
    "\n",
    "\n",
    "def match_prediction(predicted,pair,item):\n",
    "    cosin_1 = []\n",
    "    cosin_2 = []\n",
    "    for i in np.arange(len(words)):\n",
    "        if words[i][0] == word_set[pair[item]]:\n",
    "            cosin = cosine(predicted,brain_activations[i])\n",
    "            cosin_1.append(cosin)\n",
    "        if words[i][0] == word_set[pair[(item + 1) %2]]:\n",
    "            cosin = cosine(predicted,brain_activations[i])\n",
    "            cosin_2.append(cosin)\n",
    "    \n",
    "    return sum(np.asarray([c1-c2 for c1 in cosin_1 for c2 in cosin_2]) < 0) > (0.5*len(cosin_1)*len(cosin_2))\n",
    "\n",
    "\n",
    "print(match_prediction(predicted_1[0],the_pairs[0],0))\n",
    "print(match_prediction(predicted_2[0],the_pairs[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2695 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2695 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2682 - acc: 0.6437     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2686 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2687 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2684 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2690 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2687 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2692 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2690 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2680 - acc: 0.6437     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2683 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 5s - loss: 0.2679 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 5s - loss: 0.2679 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 5s - loss: 0.2675 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2677 - acc: 0.6437     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2668 - acc: 0.6408     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2673 - acc: 0.6408     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2677 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2675 - acc: 0.6408     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2687 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2685 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2681 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2683 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2681 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2677 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2688 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2686 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2669 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2670 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2679 - acc: 0.6437     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2681 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2678 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2685 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2673 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2672 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2677 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2679 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2670 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2666 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2671 - acc: 0.6552     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2680 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2678 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2682 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2683 - acc: 0.6609     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2677 - acc: 0.6580     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2676 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2675 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2681 - acc: 0.6552     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2678 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2672 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2666 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2679 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2676 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2672 - acc: 0.6552     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2674 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2689 - acc: 0.6408     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2689 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2686 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2686 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2676 - acc: 0.6379     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2682 - acc: 0.6408     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2680 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2682 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2675 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2674 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2677 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2684 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2684 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2679 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2684 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2678 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2671 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2674 - acc: 0.6437     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2671 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2675 - acc: 0.6580     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2663 - acc: 0.6437     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2664 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2685 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2670 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2657 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2664 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2675 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2666 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2665 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2669 - acc: 0.6437     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2671 - acc: 0.6552     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2668 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2675 - acc: 0.6437     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2677 - acc: 0.6437     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2676 - acc: 0.6552     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2670 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2671 - acc: 0.6552     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2674 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2665 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2668 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2672 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2669 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2661 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2665 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2669 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2673 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2665 - acc: 0.6552     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2669 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2668 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2668 - acc: 0.6580     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2680 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2675 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2668 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2667 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2670 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2671 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2673 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2675 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2668 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2667 - acc: 0.6408     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2667 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2670 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2660 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2663 - acc: 0.6408     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2672 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2673 - acc: 0.6437     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2663 - acc: 0.6437     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2662 - acc: 0.6437     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2675 - acc: 0.6437     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2668 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2681 - acc: 0.6437     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2676 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2659 - acc: 0.6437     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2667 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2675 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2669 - acc: 0.6437     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2665 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2671 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2673 - acc: 0.6580     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2670 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2660 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2661 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2671 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2664 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2659 - acc: 0.6580     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2658 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2670 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2664 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2660 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2667 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2662 - acc: 0.6580     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2665 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2674 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2673 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 5s - loss: 0.2664 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 5s - loss: 0.2663 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2672 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2665 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2665 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2673 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 5s - loss: 0.2663 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2668 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2666 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2667 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2661 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2663 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2666 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2665 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2655 - acc: 0.6437     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2657 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2669 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2660 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2660 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2661 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2664 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2664 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2684 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2668 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2658 - acc: 0.6494     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2662 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2664 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2661 - acc: 0.6552     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2667 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2668 - acc: 0.6466     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2668 - acc: 0.6466     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2666 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2650 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2655 - acc: 0.6494     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2653 - acc: 0.6552     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 4s - loss: 0.2652 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 3s - loss: 0.2651 - acc: 0.6523     \n",
      "Epoch 2/2\n",
      "348/348 [==============================] - 3s - loss: 0.2650 - acc: 0.6523     \n",
      "Epoch 1/2\n",
      "348/348 [==============================] - 4s - loss: 0.2653 - acc: 0.6552     \n",
      "Epoch 2/2\n",
      "288/348 [=======================>......] - ETA: 0s - loss: 0.2627 - acc: 0.6632"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for k in np.arange(len(the_pairs)):\n",
    "    model.reset_states()\n",
    "    model.fit(np.asarray(all_features[k]),np.asarray(all_activations[k]),nb_epoch=2)\n",
    "    predicted_1 = model.predict(np.asarray([embedded_words_2[the_pairs[k][0]]]))\n",
    "    predicted_2 = model.predict(np.asarray([embedded_words_2[the_pairs[k][1]]]))\n",
    "    res1 = match_prediction(predicted_1[0],the_pairs[k],0)\n",
    "    res2 = match_prediction(predicted_2[0],the_pairs[k],1)\n",
    "    result.append(res1)\n",
    "    result.append(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
